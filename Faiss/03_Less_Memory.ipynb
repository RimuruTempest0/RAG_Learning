{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面学习的几个索引类型为了实现向量搜索，都需要将向量存储到 Faiss 中，当向量的数量较多时就会占用更多的内存。 这也影响了 Faiss 的应用。所以，为了减少内存的占用，我们就需要会存储的向量进行重新编码、压缩，使其占用更少的存储内存，从而能够容纳更多的向量。\n",
    "\n",
    "量化技术(Product Quantization)可以使用较低精度的表示来近似向量数据，从而降低内存需求而又不牺牲准确性。 这对于大规模向量相似性搜索应用程序特别有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "data = np.random.rand(1000000, 256)\n",
    "ids = np.arange(0, 1000000)\n",
    "query_vector = np.random.rand(1, 256)\n",
    "\n",
    "\n",
    "def test01():\n",
    "\n",
    "    index = faiss.IndexFlatL2(256)\n",
    "    index = faiss.IndexIDMap(index)\n",
    "    # 添加向量\n",
    "    index.add_with_ids(data, ids)\n",
    "    # 搜索向量\n",
    "    s = time.time()\n",
    "    D, I = index.search(query_vector, k=2)\n",
    "    print('time:', time.time() - s)\n",
    "    print(D, I)\n",
    "\n",
    "    # faiss.write_index(index, 'flat.faiss')\n",
    "    # print(os.stat('flat.faiss').st_size)\n",
    "\n",
    "\n",
    "def test03():\n",
    "\n",
    "    # 第一个参数：量化参数\n",
    "    # 第二个参数：向量维度\n",
    "    # 第三个参数：质心数量\n",
    "    # 第四个参数：子空间数量（或称为段数）, 较大的值意味着将原始向量空间划分为更多的子空间进行量化，有助于减少量化误差，因为每个子空间都将被更精细地量化。\n",
    "    # 第五个参数：量化码本中码字的位数，每个段聚类的数量（8位256），决定了每个量化码字的精度，位数越多，每个码字能够表示的信息就越多，量化误差就越小。\n",
    "    quantizer = faiss.IndexFlatL2(256)\n",
    "    index = faiss.IndexIVFPQ(quantizer, 256, 100, 128, 10)\n",
    "    index.nprobe = 10\n",
    "    index.train(data)\n",
    "    index.add(data)\n",
    "    # index.add_with_ids(data, ids)\n",
    "    # 搜索向量\n",
    "    start = time.time()\n",
    "    D, I = index.search(query_vector, k=2)\n",
    "    print('time:', time.time() - start)\n",
    "    print(D, I)\n",
    "\n",
    "    # faiss.write_index(index, 'ivfpq.faiss')\n",
    "    # print(os.stat('ivfpq.faiss').st_size)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test01()\n",
    "    test03()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is from faiss github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = 64                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   78  608  159]\n",
      " [   1 1063  555  380]\n",
      " [   2  179  304  134]\n",
      " [   3  484  265   64]\n",
      " [   4  288  827  531]]\n",
      "[[1.597085  5.9489446 6.531045  6.576322 ]\n",
      " [1.3748417 6.0429764 6.437569  6.4838734]\n",
      " [1.7478867 6.1723785 6.18528   6.637947 ]\n",
      " [1.9041667 6.4681654 6.7150736 6.8242025]\n",
      " [1.6288457 5.7781396 6.384511  6.436339 ]]\n",
      "[[ 9853  8746  9900 10437]\n",
      " [10494 10507 10913 10260]\n",
      " [10719 11291 10424  9995]\n",
      " [10122 10005 11578 10125]\n",
      " [ 9229 10304  9878 10152]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlist = 100\n",
    "m = 8                             # number of subquantizers\n",
    "k = 4\n",
    "quantizer = faiss.IndexFlatL2(d)  # this remains the same\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8)\n",
    "                                    # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index.train(xb)\n",
    "index.add(xb)\n",
    "D, I = index.search(xb[:5], k) # sanity check\n",
    "print(I)\n",
    "print(D)\n",
    "index.nprobe = 10              # make comparable with experiment above\n",
    "D, I = index.search(xq, k)     # search\n",
    "print(D[-5:])\n",
    "print(I[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.092051  6.1051054 6.1229076 6.175897 ]\n",
      " [4.4511356 4.6641293 4.7500663 4.835972 ]\n",
      " [5.320959  5.686492  6.013778  6.0157094]\n",
      " [5.2807274 6.035577  6.191619  6.2410173]\n",
      " [4.917555  5.2247696 5.325024  5.629692 ]]\n",
      "[[ 9853  8746  9900 10437]\n",
      " [10494 10507 10913 10260]\n",
      " [10719 11291 10424  9995]\n",
      " [10122 10005 11578 10125]\n",
      " [ 9229 10304  9878 10152]]\n"
     ]
    }
   ],
   "source": [
    "print(D[-5:])\n",
    "print(I[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
